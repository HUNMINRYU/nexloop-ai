"""
Veo ë¹„ë””ì˜¤ ìƒì„± í´ë¼ì´ì–¸íŠ¸
Vertex AI Veo 3.1 ê¸°ë°˜ ë§ˆì¼€íŒ… ë¹„ë””ì˜¤ ìƒì„±
"""

import re
import time
from dataclasses import dataclass, field
from datetime import datetime
from typing import Callable, Optional

from config.constants import CAMERA_MOTIONS
from core.exceptions import VeoAPIError
from utils.logger import (
    get_logger,
    log_api_end,
    log_api_start,
    log_error,
    log_llm_fail,
    log_llm_request,
    log_llm_response,
    log_process,
    log_timing,
)

logger = get_logger(__name__)


# === Camera Movement Presets (Veo 3.1 í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œ ê¸°ë°˜) ===
CAMERA_MOVEMENTS = {
    "dolly_in": {
        "name": "Dolly In",
        "name_ko": "ì „ì§„ ë‹¬ë¦¬",
        "prompt": "slow dolly push-in towards the subject",
        "description": "í”¼ì‚¬ì²´ë¥¼ í–¥í•´ ë¶€ë“œëŸ½ê²Œ ì „ì§„",
    },
    "dolly_out": {
        "name": "Dolly Out",
        "name_ko": "í›„ì§„ ë‹¬ë¦¬",
        "prompt": "smooth dolly pull-out revealing the scene",
        "description": "ì¥ë©´ì„ ë“œëŸ¬ë‚´ë©° í›„ì§„",
    },
    "orbit": {
        "name": "Orbit",
        "name_ko": "360ë„ íšŒì „",
        "prompt": "slow 360Â° orbit around the subject (thats where the camera is)",
        "description": "í”¼ì‚¬ì²´ ì£¼ìœ„ë¥¼ ì›í˜•ìœ¼ë¡œ íšŒì „",
    },
    "crane_up": {
        "name": "Crane Up",
        "name_ko": "í¬ë ˆì¸ ìƒìŠ¹",
        "prompt": "cinematic crane shot rising from low to reveal the scene",
        "description": "ë‚®ì€ ìœ„ì¹˜ì—ì„œ ìƒìŠ¹í•˜ë©° ì¥ë©´ ê³µê°œ",
    },
    "crane_down": {
        "name": "Crane Down",
        "name_ko": "í¬ë ˆì¸ í•˜ê°•",
        "prompt": "elegant crane descent from high angle to eye level",
        "description": "ë†’ì€ ê°ë„ì—ì„œ ëˆˆë†’ì´ë¡œ í•˜ê°•",
    },
    "tracking": {
        "name": "Tracking",
        "name_ko": "íŠ¸ë˜í‚¹",
        "prompt": "smooth side-to-side tracking shot following the action",
        "description": "ì•¡ì…˜ì„ ë”°ë¼ê°€ëŠ” íš¡ì´ë™",
    },
    "steadicam": {
        "name": "Steadicam",
        "name_ko": "ìŠ¤í…Œë””ìº ",
        "prompt": "fluid steadicam movement with natural float",
        "description": "í”ë“¤ë¦¼ ì—†ëŠ” ë¶€ë“œëŸ¬ìš´ ì´ë™",
    },
    "handheld": {
        "name": "Handheld",
        "name_ko": "í•¸ë“œí—¬ë“œ",
        "prompt": "slightly shaky handheld shot for documentary feel",
        "description": "ë‹¤íë©˜í„°ë¦¬ ëŠë‚Œì˜ ì†ë–¨ë¦¼",
    },
    "static": {
        "name": "Static",
        "name_ko": "ê³ ì •",
        "prompt": "locked-off static shot with subtle parallax",
        "description": "ê³ ì •ëœ ì¹´ë©”ë¼ ì•µê¸€",
    },
    "pov": {
        "name": "POV",
        "name_ko": "1ì¸ì¹­ ì‹œì ",
        "prompt": "first-person POV shot from subject's perspective",
        "description": "í”¼ì‚¬ì²´ ì‹œì ì˜ 1ì¸ì¹­",
    },
    "aerial": {
        "name": "Aerial/Drone",
        "name_ko": "í•­ê³µ/ë“œë¡ ",
        "prompt": "smooth aerial drone shot descending into the scene",
        "description": "ë“œë¡  ì´¬ì˜ ëŠë‚Œì˜ í•­ê³µ ë·°",
    },
}

# === Composition Presets ===
COMPOSITIONS = {
    "wide": {
        "name": "Wide Shot",
        "name_ko": "ì™€ì´ë“œ ìƒ·",
        "prompt": "wide establishing shot",
    },
    "medium": {"name": "Medium Shot", "name_ko": "ë¯¸ë””ì—„ ìƒ·", "prompt": "medium shot"},
    "close_up": {"name": "Close-up", "name_ko": "í´ë¡œì¦ˆì—…", "prompt": "close-up shot"},
    "extreme_close_up": {
        "name": "Extreme Close-up",
        "name_ko": "ìµìŠ¤íŠ¸ë¦¼ í´ë¡œì¦ˆì—…",
        "prompt": "extreme close-up macro shot",
    },
    "over_shoulder": {
        "name": "Over Shoulder",
        "name_ko": "ì˜¤ë²„ ìˆ„ë”",
        "prompt": "over-the-shoulder shot",
    },
    "low_angle": {
        "name": "Low Angle",
        "name_ko": "ë¡œìš° ì•µê¸€",
        "prompt": "dramatic low-angle shot looking up",
    },
    "high_angle": {
        "name": "High Angle",
        "name_ko": "í•˜ì´ ì•µê¸€",
        "prompt": "top-down high-angle shot",
    },
    "dutch_angle": {
        "name": "Dutch Angle",
        "name_ko": "ë”ì¹˜ ì•µê¸€",
        "prompt": "tilted dutch angle for tension",
    },
}

# === Lighting/Mood Presets ===
LIGHTING_MOODS = {
    "golden_hour": {
        "name": "Golden Hour",
        "name_ko": "ê³¨ë“ ì•„ì›Œ",
        "prompt": "warm golden hour lighting with long shadows",
    },
    "blue_hour": {
        "name": "Blue Hour",
        "name_ko": "ë¸”ë£¨ì•„ì›Œ",
        "prompt": "cool blue hour twilight atmosphere",
    },
    "studio": {
        "name": "Studio",
        "name_ko": "ìŠ¤íŠœë””ì˜¤",
        "prompt": "professional studio lighting with key, fill and rim lights",
    },
    "dramatic": {
        "name": "Dramatic",
        "name_ko": "ë“œë¼ë§ˆí‹±",
        "prompt": "high contrast dramatic chiaroscuro lighting",
    },
    "soft": {
        "name": "Soft",
        "name_ko": "ì†Œí”„íŠ¸",
        "prompt": "soft diffused natural lighting",
    },
    "neon": {
        "name": "Neon",
        "name_ko": "ë„¤ì˜¨",
        "prompt": "vibrant neon lighting with colorful reflections",
    },
    "moody": {
        "name": "Moody",
        "name_ko": "ë¬´ë“œ",
        "prompt": "moody atmospheric lighting with haze",
    },
    "natural": {
        "name": "Natural",
        "name_ko": "ìì—°ê´‘",
        "prompt": "natural daylight from window",
    },
}

# === Audio Presets ===
AUDIO_PRESETS = {
    "cinematic": {
        "name": "Cinematic",
        "name_ko": "ì‹œë„¤ë§ˆí‹±",
        "prompt": "cinematic orchestral score with emotional swell",
    },
    "upbeat": {
        "name": "Upbeat",
        "name_ko": "ì—…ë¹„íŠ¸",
        "prompt": "upbeat modern electronic pop music",
    },
    "ambient": {
        "name": "Ambient",
        "name_ko": "ì•°ë¹„ì–¸íŠ¸",
        "prompt": "subtle ambient drone with atmospheric sounds",
    },
    "dramatic": {
        "name": "Dramatic",
        "name_ko": "ë“œë¼ë§ˆí‹±",
        "prompt": "tense dramatic score building to climax",
    },
    "calm": {
        "name": "Calm",
        "name_ko": "ì°¨ë¶„í•œ",
        "prompt": "soft piano with gentle nature sounds",
    },
    "corporate": {
        "name": "Corporate",
        "name_ko": "ê¸°ì—…ìš©",
        "prompt": "professional corporate background music",
    },
    "asmr": {
        "name": "ASMR",
        "name_ko": "ASMR",
        "prompt": "ASMR-style crisp sound effects and whispers",
    },
    "silent": {
        "name": "Silent",
        "name_ko": "ë¬´ìŒ",
        "prompt": "no background music, only ambient sounds",
    },
}


@dataclass
class AdvancedPromptBuilder:
    """
    Veo 3.1 ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ë¹Œë”
    Google AI í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œ ê¸°ë°˜ 7ê°€ì§€ ìš”ì†Œ ì¡°í•©
    """

    # í•„ìˆ˜ ìš”ì†Œ
    subject: str = ""
    action: str = ""

    # ì„ íƒ ìš”ì†Œ
    environment: str = ""
    style: str = ""
    camera_movement: str = "static"
    composition: str = "medium"
    lighting_mood: str = "natural"

    # ì˜¤ë””ì˜¤ ìš”ì†Œ
    audio_preset: str = "cinematic"
    dialogue: str = ""
    sfx: list[str] = field(default_factory=list)
    ambient: str = ""

    # ì¶”ê°€ ì˜µì…˜
    negative_prompt: str = ""
    aspect_ratio: str = "9:16"
    duration: int = 8

    def build(self) -> str:
        """ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # ë©”ì¸ ì¥ë©´ êµ¬ì„±
        scene_parts = []

        # 1. ì£¼ì œ + í™˜ê²½
        if self.subject:
            subject_line = self.subject
            if self.environment:
                subject_line += f" in {self.environment}"
            scene_parts.append(subject_line + ".")

        # 2. ë™ì‘
        if self.action:
            scene_parts.append(self.action + ".")

        # 3. ìŠ¤íƒ€ì¼
        if self.style:
            scene_parts.append(f"Style: {self.style}.")

        # 4. ì¹´ë©”ë¼ ëª¨ì…˜ + êµ¬ë„
        camera_prompt = CAMERA_MOVEMENTS.get(self.camera_movement, {}).get(
            "prompt", "static shot"
        )
        comp_prompt = COMPOSITIONS.get(self.composition, {}).get(
            "prompt", "medium shot"
        )
        scene_parts.append(f"Camera: {camera_prompt}, {comp_prompt} framing.")

        # 5. ì¡°ëª…/ë¶„ìœ„ê¸°
        mood_prompt = LIGHTING_MOODS.get(self.lighting_mood, {}).get(
            "prompt", "natural lighting"
        )
        scene_parts.append(f"Lighting: {mood_prompt}.")

        # ì˜¤ë””ì˜¤ ì„¹ì…˜
        audio_section = self._build_audio_section()

        # ìµœì¢… ì¡°í•©
        main_prompt = "\n".join(scene_parts)

        if audio_section:
            main_prompt += f"\n\nAUDIO:\n{audio_section}"

        return main_prompt

    def _build_audio_section(self) -> str:
        """ì˜¤ë””ì˜¤ ì„¹ì…˜ ë¹Œë“œ (Veo 3 ê°€ì´ë“œ í˜•ì‹)"""
        audio_parts = []

        # ëŒ€í™” (ë”°ì˜´í‘œ ì‚¬ìš©)
        if self.dialogue:
            audio_parts.append(f'- Dialogue: "{self.dialogue}"')

        # SFX (íš¨ê³¼ìŒ)
        if self.sfx:
            sfx_text = ", ".join(self.sfx)
            audio_parts.append(f"- SFX: {sfx_text}")

        # ì£¼ë³€ì†ŒìŒ/ì•°ë¹„ì–¸íŠ¸
        if self.ambient:
            audio_parts.append(f"- Ambient: {self.ambient}")

        # ë°°ê²½ìŒì•…
        audio_preset_prompt = AUDIO_PRESETS.get(self.audio_preset, {}).get("prompt", "")
        if audio_preset_prompt:
            audio_parts.append(f"- Music: {audio_preset_prompt}")

        return "\n".join(audio_parts)

    def with_product(
        self, product_name: str, category: str = ""
    ) -> "AdvancedPromptBuilder":
        """ì œí’ˆ ì´¬ì˜ìš© ì„¤ì •"""
        self.subject = f"A premium {product_name}"
        if category:
            self.subject += f" ({category} product)"
        self.environment = "modern minimalist studio with clean backdrop"
        self.lighting_mood = "studio"
        return self

    def with_marketing_hook(self, hook: str) -> "AdvancedPromptBuilder":
        """ë§ˆì¼€íŒ… í›… ì¶”ê°€"""
        self.dialogue = hook
        return self

    def with_action_style(self, style: str) -> "AdvancedPromptBuilder":
        """ë™ì‘ ìŠ¤íƒ€ì¼ ì„¤ì •"""
        style_actions = {
            "reveal": "slowly revealing its key features with elegant presentation",
            "demo": "demonstrating its functionality step by step",
            "lifestyle": "being used naturally in everyday context",
            "unboxing": "being unboxed with anticipation and excitement",
            "comparison": "showing before and after transformation",
        }
        self.action = style_actions.get(style, style)
        return self

    @staticmethod
    def get_camera_movements() -> list[dict]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ ë¬´ë¸Œë¨¼íŠ¸ ëª©ë¡"""
        return [
            {
                "key": key,
                "name": val["name"],
                "name_ko": val["name_ko"],
                "description": val["description"],
            }
            for key, val in CAMERA_MOVEMENTS.items()
        ]

    @staticmethod
    def get_compositions() -> list[dict]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ êµ¬ë„ ëª©ë¡"""
        return [
            {"key": key, "name": val["name"], "name_ko": val["name_ko"]}
            for key, val in COMPOSITIONS.items()
        ]

    @staticmethod
    def get_lighting_moods() -> list[dict]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì¡°ëª…/ë¶„ìœ„ê¸° ëª©ë¡"""
        return [
            {"key": key, "name": val["name"], "name_ko": val["name_ko"]}
            for key, val in LIGHTING_MOODS.items()
        ]

    @staticmethod
    def get_audio_presets() -> list[dict]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ í”„ë¦¬ì…‹ ëª©ë¡"""
        return [
            {"key": key, "name": val["name"], "name_ko": val["name_ko"]}
            for key, val in AUDIO_PRESETS.items()
        ]


class VeoClient:
    """Veo ë¹„ë””ì˜¤ ìƒì„± í´ë¼ì´ì–¸íŠ¸"""

    def __init__(
        self,
        project_id: str,
        location: str,
        gcs_bucket_name: str,
        model_id: str,
        vision_model_id: str = "gemini-3-pro-preview",
    ) -> None:
        self._project_id = project_id
        self._location = location
        self._gcs_bucket_name = gcs_bucket_name
        self._model_id = model_id
        self._vision_model_id = vision_model_id
        self._client = None

    def _get_client(self):
        """Vertex AI GenAI í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜ (ì§€ì—° ì´ˆê¸°í™”)"""
        if self._client is None:
            from google import genai

            self._client = genai.Client(
                vertexai=True,
                project=self._project_id,
                location=self._location,
            )
        return self._client

    def _pre_flight_safety_check(self, prompt: str) -> None:
        """Basic safety scan before sending prompt to Veo."""
        if not prompt:
            return

        blocked_terms = [
            "nsfw",
            "nude",
            "porn",
            "sex",
            "sexual",
            "gore",
            "blood",
            "hate",
            "violent",
            "violence",
        ]
        pattern = r"\b(" + "|".join(map(re.escape, blocked_terms)) + r")\b"
        if re.search(pattern, prompt, flags=re.IGNORECASE):
            raise VeoAPIError("Unsafe prompt content detected. Please revise.")
    def generate_video(
        self,
        prompt: str,
        duration_seconds: int = 8,
        resolution: str = "1080p",  # í’ˆì§ˆ ê°œì„ : 720p â†’ 1080p
        progress_callback: Optional[Callable[[str, int], None]] = None,
    ) -> bytes | str:
        """í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ë¹„ë””ì˜¤ ìƒì„±"""
        log_api_start(
            "Veo Video Generation",
            f"Duration: {duration_seconds}s, Resolution: {resolution}",
        )
        start_time = time.time()

        try:
            self._pre_flight_safety_check(prompt)
            from google.genai.types import GenerateVideosConfig

            client = self._get_client()

            date_str = datetime.now().strftime("%Y%m%d")
            output_gcs_uri = f"gs://{self._gcs_bucket_name}/videos/{date_str}/"

            if progress_callback:
                progress_callback(
                    f"Veo API ìš”ì²­ ì „ì†¡ ì¤‘... ({duration_seconds}ì´ˆ, {resolution})", 10
                )

            operation = client.models.generate_videos(
                model=self._model_id,
                prompt=prompt,
                config=GenerateVideosConfig(  # type: ignore[call-arg]
                    aspect_ratio="9:16",
                    output_gcs_uri=output_gcs_uri,
                    duration_seconds=duration_seconds,
                    generate_audio=True,
                    number_of_videos=1,
                    resolution=resolution,
                    negative_prompt="watermarks, text overlays, subtitles, blurry, low quality, distorted, morphing, flickering, jittery, shaky, nsfw, violence, deformed, ugly, bad anatomy, unnatural motion",
                    person_generation="allow_adult",
                ),
            )

            result = self._handle_operation(
                operation, duration_seconds, progress_callback, output_gcs_uri
            )

            elapsed = time.time() - start_time
            log_api_end("Veo Video Generation", duration=elapsed)
            return result

        except Exception as e:
            log_error(f"ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            raise VeoAPIError(f"ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")

    def generate_video_from_image(
        self,
        image_bytes: bytes,
        prompt: str,
        duration_seconds: int = 8,
        progress_callback: Optional[Callable[[str, int], None]] = None,
    ) -> bytes | None:
        """ì´ë¯¸ì§€ ê¸°ë°˜ ë¹„ë””ì˜¤ ìƒì„± (Image-to-Video)"""
        log_api_start("Veo I2V Generation", f"Duration: {duration_seconds}s")
        start_time = time.time()

        try:
            self._pre_flight_safety_check(prompt)
            from google.genai.types import GenerateVideosConfig

            client = self._get_client()

            # ì´ë¯¸ì§€ íŒŒíŠ¸ ìƒì„±
            try:
                import io

                from PIL import Image

                image = Image.open(io.BytesIO(image_bytes))
            except Exception as img_err:
                log_error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {img_err}")
                raise VeoAPIError("ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ ë°ì´í„°ì…ë‹ˆë‹¤.")

            date_str = datetime.now().strftime("%Y%m%d")
            output_gcs_uri = f"gs://{self._gcs_bucket_name}/videos_i2v/{date_str}/"

            if progress_callback:
                progress_callback("Veo Image-to-Video API ìš”ì²­ ì¤‘...", 10)

            enhanced_prompt = f"""
            {prompt}

            TRANSITION: Start from the provided image and naturally animate the scene.
            CAMERA: Smooth cinematic motion.
            NEGATIVE PROMPT: morphing, structural distortion, blurry, text artifacts.
            """.strip()

            operation = client.models.generate_videos(
                model=self._model_id,
                prompt=enhanced_prompt,
                config=GenerateVideosConfig(
                    input_images=[image],  # type: ignore[call-arg]
                    aspect_ratio="9:16",
                    output_gcs_uri=output_gcs_uri,
                    duration_seconds=duration_seconds,
                    generate_audio=True,
                    number_of_videos=1,
                    negative_prompt="watermarks, text, subtitles, low quality",
                    person_generation="allow_adult",
                ),
            )

            result = self._handle_operation(
                operation, duration_seconds, progress_callback, output_gcs_uri
            )

            elapsed = time.time() - start_time
            log_api_end("Veo I2V Generation", duration=elapsed)
            return result

        except Exception as e:
            log_error(f"ì´ë¯¸ì§€ ê¸°ë°˜ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            raise VeoAPIError(f"ì´ë¯¸ì§€ ê¸°ë°˜ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")

    def generate_video_with_fallback(
        self,
        phase1_prompt: str,
        phase2_prompt: str,
        duration_seconds: int = 8,
        resolution: str = "1080p",
        progress_callback: Optional[Callable[[str, int], None]] = None,
        phase2_image_bytes: Optional[bytes] = None,
    ) -> bytes | str:
        """Generate dual-phase video and fall back to phase1 on failure."""
        self._pre_flight_safety_check(phase1_prompt)
        self._pre_flight_safety_check(phase2_prompt)

        phase1_result = self.generate_video(
            prompt=phase1_prompt,
            duration_seconds=duration_seconds,
            resolution=resolution,
            progress_callback=progress_callback,
        )

        try:
            phase2_result: bytes | str | None
            if phase2_image_bytes is not None:
                phase2_result = self.generate_video_from_image(
                    image_bytes=phase2_image_bytes,
                    prompt=phase2_prompt,
                    duration_seconds=duration_seconds,
                    progress_callback=progress_callback,
                )
            else:
                phase2_result = self.generate_video(
                    prompt=phase2_prompt,
                    duration_seconds=duration_seconds,
                    resolution=resolution,
                    progress_callback=progress_callback,
                )

            return phase2_result or phase1_result
        except Exception as e:
            log_error(f"Phase 2 generation failed, falling back to phase 1: {e}")
            return phase1_result
    def generate_multimodal_prompt(
        self,
        system_instruction: str,
        user_instruction: str,
        image_bytes: bytes,
    ) -> str:
        """
        Gemini 1.5 Pro Visionì„ ì´ìš©í•œ ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
        (ì¸ë„¤ì¼ ì´ë¯¸ì§€ + ê¸°íš ì˜ë„ -> Veo í”„ë¡¬í”„íŠ¸)
        """
        log_llm_request("Veo ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ ìƒì„±", f"ì´ë¯¸ì§€ {len(image_bytes):,} bytes, ì§€ì‹œë¬¸ {len(user_instruction)}ì")
        log_api_start("Gemini Vision Analysis", "Prompt Generation")

        try:
            import io

            from PIL import Image

            client = self._get_client()

            # ì´ë¯¸ì§€ íŒŒíŠ¸
            image = Image.open(io.BytesIO(image_bytes))

            # ì±„íŒ…/ì½˜í…ì¸  ìƒì„± ìš”ì²­
            response = client.models.generate_content(
                model=self._vision_model_id,
                contents=[system_instruction, user_instruction, image],
            )

            result_text = response.text
            log_llm_response("Veo ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ ìƒì„±", f"ì‘ë‹µ {len(result_text or '')}ì")
            log_api_end("Gemini Vision Analysis")
            return result_text.strip()

        except Exception as e:
            log_llm_fail("Veo ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ ìƒì„±", str(e))
            log_error(f"ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜ì´ ì•„ë‹Œ ì—ëŸ¬ ì „íŒŒ (ìƒìœ„ì—ì„œ ì²˜ë¦¬)
            raise VeoAPIError(f"Vision API í˜¸ì¶œ ì‹¤íŒ¨: {e}")

    def _handle_operation(
        self, operation, duration_seconds, progress_callback, output_gcs_uri
    ):
        """ë¹„ë””ì˜¤ ìƒì„± ì˜¤í¼ë ˆì´ì…˜ ê³µí†µ ì²˜ë¦¬"""
        if progress_callback:
            progress_callback("ì‘ì—… ì‹œì‘ë¨", 20)

        client = self._get_client()
        max_wait = 180 if duration_seconds > 8 else 120
        waited = 0

        log_process("Veo Generating", 0, max_wait)

        while not operation.done and waited < max_wait:
            time.sleep(10)
            waited += 10
            # ë°±ê·¸ë¼ìš´ë“œ ì²´í¬ ì¤‘ ì—ëŸ¬ ë°œìƒ ì‹œ ì²˜ë¦¬
            try:
                operation = client.operations.get(operation)
            except Exception as op_err:
                log_error(f"Operation ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {op_err}")
                # ìƒíƒœ í™•ì¸ ì‹¤íŒ¨í•´ë„ ê³„ì† ëŒ€ê¸°í•´ë³¼ ìˆ˜ ìˆìŒ (ì¼ì‹œì  ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
                continue

            log_process("Veo Generating", waited, max_wait)

            if progress_callback:
                progress = min(20 + int((waited / max_wait) * 60), 80)
                progress_callback(f"ìƒì„± ì¤‘... ({waited}ì´ˆ)", progress)

        if operation.done and operation.result:
            generated_videos = getattr(operation.result, "generated_videos", None)

            if not generated_videos or len(generated_videos) == 0:
                log_error("ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return (
                    f"ì˜ìƒ ìƒì„± ì‹¤íŒ¨: ê²°ê³¼ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.\n"
                    f"GCSì—ì„œ í™•ì¸: {output_gcs_uri}"
                )

            video = generated_videos[0]
            video_uri = video.video.uri

            logger.info(f"ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {video_uri}")

            if progress_callback:
                progress_callback("ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì¤‘...", 85)

            # GCSì—ì„œ ë‹¤ìš´ë¡œë“œ
            try:
                from google.cloud import storage as gcs_storage

                download_start = time.time()
                gcs_client = gcs_storage.Client()
                path_parts = video_uri.replace("gs://", "").split("/", 1)
                bucket_name = path_parts[0]
                blob_path = path_parts[1] if len(path_parts) > 1 else ""

                bucket = gcs_client.bucket(bucket_name)
                blob = bucket.blob(blob_path)
                video_content = blob.download_as_bytes()

                # ì„ì‹œ íŒŒì¼ ì‚­ì œ (Clean up)
                try:
                    blob.delete()
                    logger.info(f"ì„ì‹œ ë¹„ë””ì˜¤ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {video_uri}")
                except Exception as del_err:
                    logger.warning(f"ì„ì‹œ ë¹„ë””ì˜¤ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ (ë¬´ì‹œë¨): {del_err}")

                log_timing("Video Download", (time.time() - download_start) * 1000)

                if progress_callback:
                    progress_callback("ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!", 100)

                return video_content

            except Exception as download_error:
                log_error(f"ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {download_error}")
                return (
                    f"ì˜ìƒ ìƒì„±ë¨ (GCS): {video_uri}\në‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {download_error}"
                )

        return f"ì˜ìƒ ìƒì„± ì§„í–‰ ì¤‘ (ë°±ê·¸ë¼ìš´ë“œ)\nGCSì—ì„œ í™•ì¸: {output_gcs_uri}"

    # === ìƒì—…ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Veo 3.1 ìµœì í™”) ===
    PRODUCT_SHOT_TEMPLATE = """
A {product} sits on a rotating pedestal inside a dark studio.
High-key rim lighting highlights its contours while a spotlight from above reveals brand details.
Camera: slow 360Â° dolly-around (thats where the camera is), 24 fps, 16:9, 1080p.
Audio: cinematic bass hit followed by subtle ambient synth.
    """.strip()

    MARKETING_SHORT_TEMPLATE = """
Create a {duration}-second vertical (9:16) short-form marketing video.

SUBJECT: {product} - a premium {category} product
ACTION: Hook viewer in first 2 seconds â†’ Demonstrate key benefit â†’ Subtle call-to-action
STYLE: Film-like quality with slight grain, professional commercial look
MOOD: {mood}

CAMERA: {camera_motion} (thats where the camera is)
RESOLUTION: 1080p, 24fps

AUDIO: {audio_style}

HOOK TEXT (spoken in first 3 seconds): "{hook}"
    """.strip()

    def generate_marketing_prompt(
        self,
        product: dict,
        insights: dict,
        hook_text: str = "",
        duration_seconds: int = 8,
        video_mode: str = "marketing",  # "marketing" | "product_360"
    ) -> str:
        """ë§ˆì¼€íŒ… ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ ìƒì„± (Veo 3.1 ìµœì í™”)"""
        p_name = product.get("name", "ì œí’ˆ")
        p_category = product.get("category", "ìƒí™œìš©í’ˆ")
        hook = insights.get("hook", hook_text) or f"{p_name}!"
        style = insights.get("style", "commercial")
        mood = insights.get("mood", "dramatic")

        # ìŠ¤íƒ€ì¼ë³„ ì¹´ë©”ë¼ ëª¨ì…˜ ë° ì˜¤ë””ì˜¤ ë§¤í•‘
        camera_motions = {
            "horror": "slow push-in with slight shake",
            "commercial": "smooth tracking shot with gentle zoom",
            "dramatic": "dynamic dolly movement with reveal",
            "calm": "static wide shot with subtle float",
        }
        audio_styles = {
            "horror": "tense ambient drone building to climax",
            "commercial": "upbeat modern electronic with positive energy",
            "dramatic": "cinematic orchestral swell",
            "calm": "soft ambient piano with nature sounds",
        }

        camera_motion = camera_motions.get(style, camera_motions["commercial"])
        audio_style = audio_styles.get(mood, audio_styles["dramatic"])

        # 360ë„ ì œí’ˆ ìƒ· ëª¨ë“œ
        if video_mode == "product_360":
            return self.PRODUCT_SHOT_TEMPLATE.format(product=p_name)

        # ë§ˆì¼€íŒ… ìˆí¼ ì˜ìƒ ëª¨ë“œ (ê¸°ë³¸)
        prompt = self.MARKETING_SHORT_TEMPLATE.format(
            duration=duration_seconds,
            product=p_name,
            category=p_category,
            mood=mood,
            camera_motion=camera_motion,
            audio_style=audio_style,
            hook=hook,
        )

        return prompt

    def get_available_motions(self) -> list[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ ëª¨ì…˜ ëª©ë¡"""
        return CAMERA_MOTIONS

    def generate_multi_video_prompts(
        self,
        product: dict,
        base_hook: str,
        duration_seconds: int = 8,
    ) -> list[dict]:
        """3ê°€ì§€ ìŠ¤íƒ€ì¼ì˜ ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        styles = [
            {
                "type": "ê³µí¬í˜•",
                "style": "horror",
                "mood": "urgent",
                "hook": f"ğŸ˜± {base_hook}",
            },
            {
                "type": "ì •ë³´í˜•",
                "style": "commercial",
                "mood": "hopeful",
                "hook": f"ğŸ’¡ {base_hook}",
            },
            {
                "type": "ìœ ë¨¸í˜•",
                "style": "commercial",
                "mood": "hopeful",
                "hook": f"ğŸ˜‚ {base_hook}",
            },
        ]

        results = []
        for s in styles:
            insights = {"hook": s["hook"], "style": s["style"], "mood": s["mood"]}
            # ì—¬ê¸°ì„œ duration_secondsë¥¼ ì „ë‹¬í•˜ì—¬ ì ì ˆí•œ í…œí”Œë¦¿ ì‚¬ìš©
            prompt = self.generate_marketing_prompt(
                product, insights, duration_seconds=duration_seconds
            )

            results.append(
                {
                    "type": s["type"],
                    "hook": s["hook"],
                    "prompt": prompt,
                    "duration": duration_seconds,
                }
            )

            logger.info(f"{s['type']} ì˜ìƒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")

        return results
