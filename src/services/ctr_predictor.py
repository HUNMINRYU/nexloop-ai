"""
CTR ì˜ˆì¸¡ ì„œë¹„ìŠ¤
ì¸ë„¤ì¼ + ì œëª© ì¡°í•© ë¶„ì„ ë° í´ë¦­ë¥  ì˜ˆì¸¡
"""

from typing import Optional

from utils.logger import get_logger, log_llm_fail, log_llm_request, log_llm_response, log_step, log_success
from core.prompts import prompt_registry
from core.prompts import ctr_prediction_prompts  # noqa: F401
from services.model_evaluator import ModelEvaluator

logger = get_logger(__name__)


class CTRPredictor:
    """AI ê¸°ë°˜ CTR ì˜ˆì¸¡ ì„œë¹„ìŠ¤"""

    def __init__(self, gemini_client=None) -> None:
        """
        Args:
            gemini_client: AI ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ ì‹œ ì‚¬ìš© (ì„ íƒ)
        """
        self._gemini = gemini_client
        self._evaluator = ModelEvaluator()

    def predict_ctr(
        self,
        title: str,
        thumbnail_description: str = "",
        competitor_titles: Optional[list[str]] = None,
        category: str = "general",
    ) -> dict:
        """
        ì œëª©ê³¼ ì¸ë„¤ì¼ ì¡°í•©ì˜ ì˜ˆìƒ CTR ê³„ì‚°

        Args:
            title: ì˜ìƒ ì œëª©
            thumbnail_description: ì¸ë„¤ì¼ ì„¤ëª… (ë˜ëŠ” ë¶„ì„ ê²°ê³¼)
            competitor_titles: ê²½ìŸ ì˜ìƒ ì œëª©ë“¤
            category: ì¹´í…Œê³ ë¦¬

        Returns:
            CTR ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        log_step("CTR ì˜ˆì¸¡", "ì‹œì‘", f"ì œëª©: {title[:30]}...")

        scores = {}

        # 1. ì œëª© ê¸¸ì´ ì ìˆ˜
        scores["title_length"] = self._score_title_length(title)

        # 2. ì´ëª¨ì§€ ì‚¬ìš© ì ìˆ˜
        scores["emoji_usage"] = self._score_emoji_usage(title)

        # 3. í›„í‚¹ ê°•ë„ ì ìˆ˜
        scores["hook_strength"] = self._score_hook_strength(title)

        # 4. ì¸ë„¤ì¼ ìš”ì†Œ ì ìˆ˜ (ì„¤ëª… ê¸°ë°˜ ì¶”ì •)
        scores["thumbnail"] = self._score_thumbnail(thumbnail_description)

        # 5. ê²½ìŸì‚¬ ëŒ€ë¹„ ì°¨ë³„í™” ì ìˆ˜
        scores["differentiation"] = self._score_differentiation(
            title, competitor_titles or []
        )

        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        total_score = (
            scores["title_length"] * 0.15
            + scores["emoji_usage"] * 0.10
            + scores["hook_strength"] * 0.25
            + scores["thumbnail"] * 0.30
            + scores["differentiation"] * 0.20
        )

        # CTR ë²”ìœ„ë¡œ ë³€í™˜ (2% ~ 15%)
        predicted_ctr = 2 + (total_score / 100) * 13

        result = {
            "predicted_ctr": round(predicted_ctr, 2),
            "ctr_range": self._get_ctr_range(predicted_ctr),
            "total_score": round(total_score, 1),
            "breakdown": scores,
            "recommendations": self._generate_recommendations(scores),
            "grade": self._get_grade(total_score),
        }

        log_success(f"CTR ì˜ˆì¸¡ ì™„ë£Œ: {result['predicted_ctr']}% ({result['grade']})")
        self._evaluator.log_prediction(
            model_name="ctr_hybrid",
            input_data={"title": title, "thumbnail_description": thumbnail_description},
            output=result,
        )
        return result

    def _score_title_length(self, title: str) -> float:
        """ì œëª© ê¸¸ì´ ì ìˆ˜ (0-100)"""
        length = len(title)
        optimal_min, optimal_max = 30, 60

        if optimal_min <= length <= optimal_max:
            return 100.0
        elif length < optimal_min:
            return max(0, 100 - (optimal_min - length) * 3)
        else:
            return max(0, 100 - (length - optimal_max) * 2)

    def _score_emoji_usage(self, title: str) -> float:
        """ì´ëª¨ì§€ ì‚¬ìš© ì ìˆ˜ (0-100)"""
        import re

        # ì´ëª¨ì§€ íŒ¨í„´
        emoji_pattern = re.compile(
            "["
            "\U0001f600-\U0001f64f"  # emoticons
            "\U0001f300-\U0001f5ff"  # symbols & pictographs
            "\U0001f680-\U0001f6ff"  # transport & map
            "\U0001f1e0-\U0001f1ff"  # flags
            "\U00002702-\U000027b0"
            "\U000024c2-\U0001f251"
            "]+",
            flags=re.UNICODE,
        )

        emojis = emoji_pattern.findall(title)
        count = len(emojis)

        if count == 0:
            return 60.0  # ì´ëª¨ì§€ ì—†ìŒ - ë³´í†µ
        elif 1 <= count <= 3:
            return 100.0  # ìµœì 
        elif count <= 5:
            return 80.0  # ì•½ê°„ ë§ìŒ
        else:
            return 50.0  # ë„ˆë¬´ ë§ìŒ

    def _score_hook_strength(self, title: str) -> float:
        """í›„í‚¹ ê°•ë„ ì ìˆ˜ (0-100)"""
        strong_hooks = ["ë¹„ë°€", "ì¶©ê²©", "ë°˜ì „", "ê¿€íŒ", "í•„ìˆ˜", "ì£¼ì˜", "ê²½ê³ ", "ê¸´ê¸‰"]
        medium_hooks = ["ë°©ë²•", "ì´ìœ ", "ì§„ì‹¤", "ì‚¬ì‹¤", "íš¨ê³¼", "ê²°ê³¼", "ë¹„êµ"]
        weak_hooks = ["ì¶”ì²œ", "ì†Œê°œ", "ë¦¬ë·°", "í›„ê¸°"]

        title_lower = title.lower()

        # ê°•í•œ í›„í‚¹ í‚¤ì›Œë“œ ì²´í¬
        strong_count = sum(1 for h in strong_hooks if h in title_lower)
        medium_count = sum(1 for h in medium_hooks if h in title_lower)
        weak_count = sum(1 for h in weak_hooks if h in title_lower)

        score = 50.0  # ê¸°ë³¸
        score += strong_count * 20
        score += medium_count * 10
        score += weak_count * 5

        # ìˆ«ì ì‚¬ìš© ë³´ë„ˆìŠ¤ (ì˜ˆ: "3ê°€ì§€ ë°©ë²•")
        if any(c.isdigit() for c in title):
            score += 10

        # ë¬¼ìŒí‘œ ì‚¬ìš© ë³´ë„ˆìŠ¤
        if "?" in title:
            score += 5

        return min(100.0, score)

    def _score_thumbnail(self, description: str) -> float:
        """ì¸ë„¤ì¼ ì ìˆ˜ (ì„¤ëª… ê¸°ë°˜ ì¶”ì •)"""
        if not description:
            return 70.0  # ì„¤ëª… ì—†ìœ¼ë©´ í‰ê· 

        score = 50.0
        desc_lower = description.lower()

        # ê¸ì •ì  ìš”ì†Œ
        if any(word in desc_lower for word in ["ì–¼êµ´", "face", "ì¸ë¬¼", "ì‚¬ëŒ"]):
            score += 15
        if any(word in desc_lower for word in ["í…ìŠ¤íŠ¸", "text", "ê¸€ì"]):
            score += 10
        if any(word in desc_lower for word in ["ë°ì€", "bright", "ì„ ëª…", "contrast"]):
            score += 10
        if any(word in desc_lower for word in ["í™”ì‚´í‘œ", "arrow", "ê°•ì¡°"]):
            score += 5
        if any(word in desc_lower for word in ["before", "after", "ë¹„êµ", "ì „í›„"]):
            score += 10

        return min(100.0, score)

    def _score_differentiation(self, title: str, competitor_titles: list[str]) -> float:
        """ê²½ìŸì‚¬ ëŒ€ë¹„ ì°¨ë³„í™” ì ìˆ˜"""
        if not competitor_titles:
            return 75.0  # ë¹„êµ ëŒ€ìƒ ì—†ìŒ

        # ì œëª© ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê²¹ì¹¨)
        title_words = set(title.lower().split())

        similarity_scores = []
        for comp_title in competitor_titles[:5]:
            comp_words = set(comp_title.lower().split())
            if title_words and comp_words:
                overlap = len(title_words & comp_words) / len(title_words | comp_words)
                similarity_scores.append(overlap)

        if not similarity_scores:
            return 75.0

        avg_similarity = sum(similarity_scores) / len(similarity_scores)

        # ì°¨ë³„í™” ì ìˆ˜ (ìœ ì‚¬ë„ê°€ ë‚®ì„ìˆ˜ë¡ ë†’ìŒ)
        differentiation = (1 - avg_similarity) * 100
        return max(50.0, min(100.0, differentiation))

    def _get_ctr_range(self, ctr: float) -> str:
        """CTR ë²”ìœ„ ë ˆì´ë¸”"""
        if ctr >= 10:
            return "ë§¤ìš° ë†’ìŒ (ìƒìœ„ 5%)"
        elif ctr >= 7:
            return "ë†’ìŒ (ìƒìœ„ 20%)"
        elif ctr >= 5:
            return "í‰ê·  (50%)"
        elif ctr >= 3:
            return "ë‚®ìŒ (í•˜ìœ„ 30%)"
        else:
            return "ë§¤ìš° ë‚®ìŒ (í•˜ìœ„ 10%)"

    def _get_grade(self, score: float) -> str:
        """ì ìˆ˜ ê¸°ë°˜ ë“±ê¸‰"""
        if score >= 90:
            return "S"
        elif score >= 80:
            return "A"
        elif score >= 70:
            return "B"
        elif score >= 60:
            return "C"
        else:
            return "D"

    def _generate_recommendations(self, scores: dict) -> list[str]:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        if scores.get("title_length", 100) < 70:
            recommendations.append("ğŸ“ ì œëª© ê¸¸ì´ë¥¼ 30-60ì ì‚¬ì´ë¡œ ì¡°ì •í•˜ì„¸ìš”")

        if scores.get("emoji_usage", 100) < 70:
            recommendations.append("ğŸ˜Š ì´ëª¨ì§€ 1-3ê°œë¥¼ ì¶”ê°€í•˜ì—¬ ëˆˆì— ë„ê²Œ ë§Œë“œì„¸ìš”")

        if scores.get("hook_strength", 100) < 70:
            recommendations.append(
                "ğŸ£ 'ë¹„ë°€', 'ê¿€íŒ', 'í•„ìˆ˜' ê°™ì€ í›„í‚¹ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”"
            )

        if scores.get("thumbnail", 100) < 70:
            recommendations.append("ğŸ–¼ï¸ ì¸ë„¤ì¼ì— ì–¼êµ´/ëŒ€ë¹„/í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ë¥¼ ì¶”ê°€í•˜ì„¸ìš”")

        if scores.get("differentiation", 100) < 70:
            recommendations.append("ğŸ’¡ ê²½ìŸ ì˜ìƒê³¼ ì°¨ë³„í™”ëœ ì•µê¸€ì„ ì‹œë„í•˜ì„¸ìš”")

        if not recommendations:
            recommendations.append("âœ… ëª¨ë“  ìš”ì†Œê°€ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")

        return recommendations

    def compare_variations(self, variations: list[dict]) -> list[dict]:
        """
        ì—¬ëŸ¬ ë²„ì „ì˜ ì œëª©/ì¸ë„¤ì¼ ë¹„êµ

        Args:
            variations: [{title, thumbnail_description, ...}] ë¦¬ìŠ¤íŠ¸

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ + ìˆœìœ„ ë¦¬ìŠ¤íŠ¸
        """
        results = []

        for i, var in enumerate(variations):
            prediction = self.predict_ctr(
                title=var.get("title", ""),
                thumbnail_description=var.get("thumbnail_description", ""),
            )
            prediction["variation_id"] = i + 1
            prediction["title"] = var.get("title", "")
            results.append(prediction)

        # CTR ìˆœìœ¼ë¡œ ì •ë ¬
        results.sort(key=lambda x: x["predicted_ctr"], reverse=True)

        # ìˆœìœ„ ì¶”ê°€
        for rank, result in enumerate(results, 1):
            result["rank"] = rank

        return results

    async def predict_with_ai(
        self,
        title: str,
        thumbnail_bytes: Optional[bytes] = None,
        category: str = "general",
        top_insights: Optional[list[dict]] = None,
    ) -> dict:
        """
        AIë¥¼ í™œìš©í•œ ì‹¬ì¸µ CTR ì˜ˆì¸¡

        Args:
            title: ì˜ìƒ ì œëª©
            thumbnail_bytes: ì¸ë„¤ì¼ ì´ë¯¸ì§€ ë°”ì´íŠ¸
            category: ì¹´í…Œê³ ë¦¬
            top_insights: X-Algorithm í•µì‹¬ ì¸ì‚¬ì´íŠ¸

        Returns:
            AI ë¶„ì„ í¬í•¨ ì˜ˆì¸¡ ê²°ê³¼
        """
        # ê¸°ë³¸ ì˜ˆì¸¡ ë¨¼ì € ìˆ˜í–‰
        basic_prediction = self.predict_ctr(title)

        if not self._gemini:
            return basic_prediction

        insights_text = ""
        if top_insights:
            import json
            insights_text = f"\n## X-Algorithm í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (ì°¸ê³ ìš©)\n{json.dumps(top_insights, ensure_ascii=False, indent=2)}\n"

        prompt = prompt_registry.get("ctr.prediction").render(
            insights_text=insights_text,
            title=title,
            category=category,
        )
        log_llm_request("CTR AI ë¶„ì„", f"ì œëª©: {title[:30]}...")

        try:
            ai_response = await self._gemini.generate_content_async(prompt)
            log_llm_response("CTR AI ë¶„ì„", f"ì‘ë‹µ {len(ai_response or '')}ì")
            basic_prediction["ai_analysis"] = ai_response
            return basic_prediction
        except Exception as e:
            log_llm_fail("CTR AI ë¶„ì„", str(e))
            logger.warning(f"AI CTR ë¶„ì„ ì‹¤íŒ¨: {e}")
            return basic_prediction
